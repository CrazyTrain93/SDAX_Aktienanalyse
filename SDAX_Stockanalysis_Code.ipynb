{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDAX Stock Analysis Sheet \n",
    "\n",
    "### Welcome to my first self-designed and realised Github project.\n",
    "\n",
    "<b> The aim of this project was to create a stock analysis dashboard with the help of which I am able to find interesting stocks with a quick glance, where a deeper analysis could be worthwhile. </b>\n",
    "\n",
    "DISCLAIMER!!! No investment advice - share trading can involve the risk of a total loss!\n",
    "This project is only a demonstration of skills and technologies in the context of a project that could be used in the real world.\n",
    "\n",
    "I use it myself to make a pre-selection of stocks that I would like to analyse in more detail.\n",
    "\n",
    "<b> The project can be applied to all stocks in the world without much effort. All I need is the Yahoo Finance link to the stock and the Google Finance ticker of the stock (we use this later in Google Sheets)</b>\n",
    "\n",
    "## See the Final Results of the Project here: \n",
    "\n",
    "<b> Use This Sheet for Analysis (final Dashboard):</b> https://docs.google.com/spreadsheets/d/133GuIO_aHu6SBelkRmA2gvcuh4TmS9st-rjIRDFON-k/edit#gid=0\n",
    "\n",
    "<b> In This Sheet i write the Data with this Code (Data Dump or my small own Database ;) </b> https://docs.google.com/spreadsheets/d/19yWEwyOEKP_sS_w2laKwD7uIcrST97LpABUaXEw8tQQ/edit#gid=0\n",
    "\n",
    "\n",
    "To run This Code fully, you need a Google Cloud Service Account with an activated Google Sheets API Key and Download the .json file of your Credentials and put them into your Folder - I will comment this at the piece of Code where u need it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But for now lets start to Code! read the README File if u want to know more about the Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all libraries we need for the Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for Webscraping, Data Manipulation and Google Sheets + Cloud API\n",
    "\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "\n",
    "# U will need this later, to get access to the Google Sheets with the API key\n",
    "# pip install gspread oauth2client pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Link list of Stocks u want to Scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for single link testing (for API Connection testing) = \"https://finance.yahoo.com/quote/HLAG.DE/key-statistics?p=HLAG.DE\"\n",
    "\n",
    "# Yahoo Finance Links to the Stocks we want to Scrape Data\n",
    "\n",
    "link_list = [\"https://finance.yahoo.com/quote/1U1.DE/key-statistics?p=1U1.DE\", \"https://finance.yahoo.com/quote/ADN1.DE/key-statistics?p=ADN1.DE\", \"https://finance.yahoo.com/quote/ADTN/key-statistics?p=ADTN\", \"https://finance.yahoo.com/quote/ADV.DE/key-statistics?p=ADV.DE\", \"https://finance.yahoo.com/quote/AAD.DE/key-statistics?p=AAD.DE\", \"https://finance.yahoo.com/quote/AOF.DE/key-statistics?p=AOF.DE\", \"https://finance.yahoo.com/quote/AG1.DE/key-statistics?p=AG1.DE\", \"https://finance.yahoo.com/quote/BYW.DE/key-statistics?p=BYW.DE\", \"https://finance.yahoo.com/quote/BFSA.DE/key-statistics?p=BFSA.DE\", \"https://finance.yahoo.com/quote/GBF.DE/key-statistics?p=GBF.DE\", \"https://finance.yahoo.com/quote/BVB.DE/key-statistics?p=BVB.DE\", \"https://finance.yahoo.com/quote/COK.DE/key-statistics?p=COK.DE\", \"https://finance.yahoo.com/quote/CEC.DE/key-statistics?p=CEC.DE\", \"https://finance.yahoo.com/quote/CWC.DE/key-statistics?p=CWC.DE\", \"https://finance.yahoo.com/quote/COP.DE/key-statistics?p=COP.DE\", \"https://finance.yahoo.com/quote/DMP.DE/key-statistics?p=DMP.DE\", \"https://finance.yahoo.com/quote/DBAN.DE/key-statistics?p=DBAN.DE\", \"https://finance.yahoo.com/quote/DWNI.DE/key-statistics?p=DWNI.DE\", \"https://finance.yahoo.com/quote/DEZ.DE/key-statistics?p=DEZ.DE\", \"https://finance.yahoo.com/quote/DRW3.DE/key-statistics?p=DRW3.DE\", \"https://finance.yahoo.com/quote/DUE.DE/key-statistics?p=DUE.DE\", \"https://finance.yahoo.com/quote/DWS.DE/key-statistics?p=DWS.DE\", \"https://finance.yahoo.com/quote/EUZ.DE/key-statistics?p=EUZ.DE\", \"https://finance.yahoo.com/quote/ELG.DE/key-statistics?p=ELG.DE\", \"https://finance.yahoo.com/quote/EKT.DE/key-statistics?p=EKT.DE\", \"https://finance.yahoo.com/quote/FIE.DE/key-statistics?p=FIE.DE\", \"https://finance.yahoo.com/quote/FTK.DE/key-statistics?p=FTK.DE\", \"https://finance.yahoo.com/quote/GFT.DE/key-statistics?p=GFT.DE\", \"https://finance.yahoo.com/quote/GYC.DE/key-statistics?p=GYC.DE\", \"https://finance.yahoo.com/quote/GLJ.DE/key-statistics?p=GLJ.DE\", \"https://finance.yahoo.com/quote/HABA.DE/key-statistics?p=HABA.DE\", \"https://finance.yahoo.com/quote/HDD.DE/key-statistics?p=HDD.DE\", \"https://finance.yahoo.com/quote/HBH.DE/key-statistics?p=HBH.DE\", \"https://finance.yahoo.com/quote/HYQ.DE/key-statistics?p=HYQ.DE\", \"https://finance.yahoo.com/quote/INH.DE/key-statistics?p=INH.DE\", \"https://finance.yahoo.com/quote/IOS.DE/key-statistics?p=IOS.DE\", \"https://finance.yahoo.com/quote/JST.DE/key-statistics?p=JST.DE\", \"https://finance.yahoo.com/quote/KCO.DE/key-statistics?p=KCO.DE\", \"https://finance.yahoo.com/quote/KTN.DE/key-statistics?p=KTN.DE\", \"https://finance.yahoo.com/quote/KSB3.DE/key-statistics?p=KSB3.DE\", \"https://finance.yahoo.com/quote/KWS.DE/key-statistics?p=KWS.DE\", \"https://finance.yahoo.com/quote/B4B.DE/key-statistics?p=B4B.DE\", \"https://finance.yahoo.com/quote/MOR.DE/key-statistics?p=MOR.DE\", \"https://finance.yahoo.com/quote/MUX.DE/key-statistics?p=MUX.DE\", \"https://finance.yahoo.com/quote/NA9.DE/key-statistics?p=NA9.DE\", \"https://finance.yahoo.com/quote/NOEJ.DE/key-statistics?p=NOEJ.DE\", \"https://finance.yahoo.com/quote/PAT.DE/key-statistics?p=PAT.DE\", \"https://finance.yahoo.com/quote/PBB.DE/key-statistics?p=PBB.DE\", \"https://finance.yahoo.com/quote/PFV.DE/key-statistics?p=PFV.DE\", \"https://finance.yahoo.com/quote/PNE3.DE/key-statistics?p=PNE3.DE\", \"https://finance.yahoo.com/quote/PSM.DE/key-statistics?p=PSM.DE\", \"https://finance.yahoo.com/quote/TPE.DE/key-statistics?p=TPE.DE\", \"https://finance.yahoo.com/quote/SFQ.DE/key-statistics?p=SFQ.DE\", \"https://finance.yahoo.com/quote/SZG.DE/key-statistics?p=SZG.DE\", \"https://finance.yahoo.com/quote/SHA.DE/key-statistics?p=SHA.DE\", \"https://finance.yahoo.com/quote/1SXP.DE/key-statistics?p=1SXP.DE\", \"https://finance.yahoo.com/quote/F3C.DE/key-statistics?p=F3C.DE\", \"https://finance.yahoo.com/quote/SGL.DE/key-statistics?p=SGL.DE\", \"https://finance.yahoo.com/quote/STO3.DE/key-statistics?p=STO3.DE\", \"https://finance.yahoo.com/quote/SBS.DE/key-statistics?p=SBS.DE\", \"https://finance.yahoo.com/quote/SZU.DE/key-statistics?p=SZU.DE\", \"https://finance.yahoo.com/quote/SMHN.DE/key-statistics?p=SMHN.DE\", \"https://finance.yahoo.com/quote/SYAB.DE/key-statistics?p=SYAB.DE\", \"https://finance.yahoo.com/quote/NCH2.DE/key-statistics?p=NCH2.DE\", \"https://finance.yahoo.com/quote/8TRA.DE/key-statistics?p=8TRA.DE\", \"https://finance.yahoo.com/quote/VAR1.DE/key-statistics?p=VAR1.DE\", \"https://finance.yahoo.com/quote/VBK.DE/key-statistics?p=VBK.DE\", \"https://finance.yahoo.com/quote/VOS.DE/key-statistics?p=VOS.DE\", \"https://finance.yahoo.com/quote/WAC.DE/key-statistics?p=WAC.DE\", \"https://finance.yahoo.com/quote/WUW.DE/key-statistics?p=WUW.DE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a valid Header for our Scraper, otherwise the Websites may block you, when you sent too much requests with an empty header\n",
    "\n",
    "headers_http = {\"User-Agent\" : \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:99.0) Gecko/20100101 Firefox/99.0\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the Table Header Names (Name of Financial Metric)\n",
    "This code was used, to extract the Column Headers, which i fill in here hardcoded, because its the same Metric Columns in every Stock.\n",
    "\n",
    "If you want to extract the Column Names on your own, you can run this code to get them \n",
    "\n",
    "```python\n",
    "# This is the Code block to extract Table Columns\n",
    "finance_names = []\n",
    "\n",
    "# noticed only 50 of 60 headlines were found - 10 have other class name (for no reason) catched them with RegEX -- (\"td\", class_=\"Pos(st) Start(0) Bgc($lv2BgColor) fi-row:h_Bgc($hoverBgColor) Pend(10px)\")\n",
    "\n",
    "class_pattern = re.compile(r\"(^|\\s)Pos\\(st\\) Start\\(0\\) Bgc\\(\\$lv2BgColor\\) fi-row:h_Bgc\\(\\$hoverBgColor\\) Pend\\(10px\\)(\\s|$)\")\n",
    "\n",
    "# Scrape all Column Names of the Financial Metric from Web\n",
    "column_names = soup.find_all(\"td\", class_=class_pattern)\n",
    "for element in column_names:\n",
    "    finance_names.append(element.text)\n",
    "\n",
    "# Adjust Column Headers removing the whitespace\n",
    "for idx, element in enumerate(finance_names):\n",
    "    finance_names[idx] =  element.replace(\" \",\"_\")\n",
    "print(finance_names) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hardcoded Column Names (after extracting them with the Code above)\n",
    "\n",
    "headers_column = ['Market_Cap_(intraday)_', 'Enterprise_Value_', 'Trailing_P/E_', 'Forward_P/E_', 'PEG_Ratio_(5_yr_expected)_', 'Price/Sales_(ttm)', \n",
    "                  'Price/Book_(mrq)', 'Enterprise_Value/Revenue_', 'Enterprise_Value/EBITDA_', 'Beta_(5Y_Monthly)_', '52-Week_Change_3', \n",
    "                  'S&P500_52-Week_Change_3', '52_Week_High_3', '52_Week_Low_3', '50-Day_Moving_Average_3', '200-Day_Moving_Average_3', 'Avg_Vol_(3_month)_3', \n",
    "                  'Avg_Vol_(10_day)_3', 'Shares_Outstanding_5', 'Implied_Shares_Outstanding_6', 'Float_8', '%_Held_by_Insiders_1', '%_Held_by_Institutions_1', \n",
    "                  'Shares_Short__4', 'Short_Ratio__4', 'Short_%_of_Float__4', 'Short_%_of_Shares_Outstanding__4', 'Shares_Short_(prior_month_)_4', \n",
    "                  'Forward_Annual_Dividend_Rate_4', 'Forward_Annual_Dividend_Yield_4', 'Trailing_Annual_Dividend_Rate_3', 'Trailing_Annual_Dividend_Yield_3', \n",
    "                  '5_Year_Average_Dividend_Yield_4', 'Payout_Ratio_4', 'Dividend_Date_3', 'Ex-Dividend_Date_4', 'Last_Split_Factor_2', 'Last_Split_Date_3', \n",
    "                  'Fiscal_Year_Ends_', 'Most_Recent_Quarter_(mrq)', 'Profit_Margin_', 'Operating_Margin_(ttm)', 'Return_on_Assets_(ttm)', 'Return_on_Equity_(ttm)', \n",
    "                  'Revenue_(ttm)', 'Revenue_Per_Share_(ttm)', 'Quarterly_Revenue_Growth_(yoy)', 'Gross_Profit_(ttm)', 'EBITDA_', 'Net_Income_Avi_to_Common_(ttm)', \n",
    "                  'Diluted_EPS_(ttm)', 'Quarterly_Earnings_Growth_(yoy)', 'Total_Cash_(mrq)', 'Total_Cash_Per_Share_(mrq)', 'Total_Debt_(mrq)', 'Total_Debt/Equity_(mrq)', \n",
    "                  'Current_Ratio_(mrq)', 'Book_Value_Per_Share_(mrq)', 'Operating_Cash_Flow_(ttm)', 'Levered_Free_Cash_Flow_(ttm)']\n",
    "\n",
    "# define the Lists, where we write the Webscraping Data in\n",
    "data_list = []\n",
    "finance_numbers = []\n",
    "name_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract All financial Metrics from the Website for each Stock\n",
    "\n",
    "Now that we have the Link List and the Column Names, we will get the Data from Yahoo Finance.\n",
    "\n",
    "<b> Get Ready for the Main Code Block of the Project. I will add comments to every important step.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script Run Successfully!\n"
     ]
    }
   ],
   "source": [
    "# Go over each Link in the List and send a request with our defined Header\n",
    "# If the Response is 200 OK. Process with the Script otherwise print a Error Message\n",
    "# with the soup Variable we get the Webiste content for each Link\n",
    "\n",
    "for link in link_list:\n",
    "    r = requests.get(link, headers=headers_http)\n",
    "    if r.status_code == 200:\n",
    "        soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "        \n",
    "        # Get the beautiful Soup Object for all Finance Metrics with its HTMl Class\n",
    "        finanz_zahlen = soup.find_all(\"td\", class_=\"Fw(500) Ta(end) Pstart(10px) Miw(60px)\", string=True)\n",
    "        # Get the beautiful Soup Object for the Company Name of the Link\n",
    "        firmenname = soup.find_all(\"h1\", class_=\"D(ib) Fz(18px)\", string=True)\n",
    "\n",
    "        finance_numbers = []  # Initialize finance_numbers within the loop\n",
    "        \n",
    "        # Go over the finance Metrics in our Soup Object and append them to a list\n",
    "        # Because every Value are Strings from the Soup Object\n",
    "        # Yahoo Finance Gives Back Numbers like \"24,3M\" i convert Million, Billion etc. into floats\n",
    "\n",
    "        for element in finanz_zahlen:\n",
    "            finance_numbers.append(element.text)\n",
    "\n",
    "        for idx, element in enumerate(finance_numbers):\n",
    "\n",
    "            # Converts M into float Million and so on...\n",
    "            if element.endswith(\"M\"):\n",
    "                finance_numbers[idx] = float(element[:-1]) * 1e6\n",
    "            elif element.endswith(\"B\"):\n",
    "                finance_numbers[idx] = float(element[:-1]) * 1e9\n",
    "            elif element.endswith(\"k\"):\n",
    "                finance_numbers[idx] = float(element[:-1]) * 1e3\n",
    "            elif element.endswith(\"%\"):\n",
    "                finance_numbers[idx] = element\n",
    "\n",
    "        data_list.extend(finance_numbers)  # Append finance_numbers to data_list after processing\n",
    "        name_list.extend(firmenname)  # Append Company name to names list after processing\n",
    "\n",
    "    else:\n",
    "        print(\"Seems like there was an Error\")\n",
    "\n",
    "# Converting Finance Numbers into a Numpy Array and Reshape it into 60 columns (this sorts them as well)\n",
    "data_array = np.array(data_list)\n",
    "data_array = data_array.reshape(len(link_list), 60)\n",
    "# Write the Array with our financial Metrics into the Dataframe\n",
    "df_finance = pd.DataFrame(data_array, columns=headers_column)  \n",
    "\n",
    "# do the same for the Company name\n",
    "name_array = np.array(name_list)\n",
    "name_array = name_array.reshape(len(link_list), 1)\n",
    "df_names = pd.DataFrame(name_array, columns=[\"Company Name\"])\n",
    "\n",
    "# Get 1 Column for the Links, to look up further Data if Stock has good measurements\n",
    "\n",
    "df_links = pd.DataFrame(link_list, columns=[\"Link_Yahoo_Finance\"])\n",
    "\n",
    "# create final DF to write into Google Sheets later\n",
    "df_final = pd.concat([df_names, df_links, df_finance], axis=1)\n",
    "\n",
    "# just a quick test if whole list was successfully crawled\n",
    "print(\"Script Run Successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now you need your Google Cloud Service Account and working Google Sheets API Credentials. Download the JSON File \n",
    "\n",
    "You can do this here your Google Cloud Console Dashboard: https://console.cloud.google.com/\n",
    "For the Steps to Create Cloud API Credentials read the README File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spreadsheetId': '19yWEwyOEKP_sS_w2laKwD7uIcrST97LpABUaXEw8tQQ',\n",
       " 'updatedRange': 'Sheet1!A1:BJ71',\n",
       " 'updatedRows': 71,\n",
       " 'updatedColumns': 62,\n",
       " 'updatedCells': 4402}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the scope\n",
    "scope = ['https://www.googleapis.com/auth/drive', 'https://www.googleapis.com/auth/spreadsheets']\n",
    "\n",
    "# Insert your Google API JSON File here! Replace my old one (and add it to your Project Folder)\n",
    "path = \"evident-catcher-416200-7712669a9428.json\" \n",
    "\n",
    "# Authenticate using credentials\n",
    "credentials = ServiceAccountCredentials.from_json_keyfile_name(path, scope)\n",
    "client = gspread.authorize(credentials)\n",
    "\n",
    "# Open the Google Sheet Replace SDAX_DATA_DUMP with the Name of your Sheet\n",
    "sheet = client.open('SDAX_Data_Dump').sheet1\n",
    "\n",
    "\n",
    "# Write DataFrame to Google Sheet\n",
    "# First, clear the existing contents of the sheet\n",
    "sheet.clear()\n",
    "# Then, write the DataFrame to the sheet\n",
    "sheet.update([df_final.columns.values.tolist()] + df_final.values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now the Google Sheet is refreshed and you have the Actual Data for your Stock Analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
